{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecfe7b42",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1fa739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "# %pip install matplotlib\n",
    "# %pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06728a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f170dfe",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dacfc89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (9840, 32)\n",
      "\n",
      "First 5 rows of training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>TimeElapsed</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>137696.0</td>\n",
       "      <td>2.065791</td>\n",
       "      <td>-0.065613</td>\n",
       "      <td>-1.130470</td>\n",
       "      <td>0.384728</td>\n",
       "      <td>-0.075736</td>\n",
       "      <td>-1.128309</td>\n",
       "      <td>0.186186</td>\n",
       "      <td>-0.326402</td>\n",
       "      <td>0.551486</td>\n",
       "      <td>0.071902</td>\n",
       "      <td>-0.873314</td>\n",
       "      <td>0.389151</td>\n",
       "      <td>0.088783</td>\n",
       "      <td>0.267724</td>\n",
       "      <td>0.051437</td>\n",
       "      <td>-0.061622</td>\n",
       "      <td>-0.341495</td>\n",
       "      <td>-0.820560</td>\n",
       "      <td>0.200598</td>\n",
       "      <td>-0.212461</td>\n",
       "      <td>-0.296821</td>\n",
       "      <td>-0.728288</td>\n",
       "      <td>0.318849</td>\n",
       "      <td>-0.110236</td>\n",
       "      <td>-0.280067</td>\n",
       "      <td>0.204709</td>\n",
       "      <td>-0.071613</td>\n",
       "      <td>-0.060814</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161961.0</td>\n",
       "      <td>2.095037</td>\n",
       "      <td>-1.175449</td>\n",
       "      <td>-1.520765</td>\n",
       "      <td>-0.918477</td>\n",
       "      <td>-0.481096</td>\n",
       "      <td>-0.488949</td>\n",
       "      <td>-0.525732</td>\n",
       "      <td>-0.273566</td>\n",
       "      <td>-0.063873</td>\n",
       "      <td>0.759856</td>\n",
       "      <td>-1.797146</td>\n",
       "      <td>-0.866861</td>\n",
       "      <td>0.405156</td>\n",
       "      <td>-0.354675</td>\n",
       "      <td>-0.022158</td>\n",
       "      <td>1.091197</td>\n",
       "      <td>-0.107480</td>\n",
       "      <td>-0.757384</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.181253</td>\n",
       "      <td>0.565300</td>\n",
       "      <td>1.580267</td>\n",
       "      <td>-0.318744</td>\n",
       "      <td>-0.901549</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>0.302833</td>\n",
       "      <td>-0.034751</td>\n",
       "      <td>-0.058508</td>\n",
       "      <td>104.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>153055.0</td>\n",
       "      <td>-0.584961</td>\n",
       "      <td>-4.600653</td>\n",
       "      <td>-2.430893</td>\n",
       "      <td>0.969314</td>\n",
       "      <td>-0.657150</td>\n",
       "      <td>2.225950</td>\n",
       "      <td>0.971258</td>\n",
       "      <td>0.299291</td>\n",
       "      <td>1.152448</td>\n",
       "      <td>-0.865479</td>\n",
       "      <td>0.643267</td>\n",
       "      <td>0.995614</td>\n",
       "      <td>-0.669748</td>\n",
       "      <td>0.648798</td>\n",
       "      <td>0.435696</td>\n",
       "      <td>-0.542873</td>\n",
       "      <td>0.119842</td>\n",
       "      <td>-0.757992</td>\n",
       "      <td>-0.603119</td>\n",
       "      <td>2.248672</td>\n",
       "      <td>0.461198</td>\n",
       "      <td>-1.349655</td>\n",
       "      <td>-0.676798</td>\n",
       "      <td>-0.975495</td>\n",
       "      <td>-0.972022</td>\n",
       "      <td>-1.120256</td>\n",
       "      <td>-0.154142</td>\n",
       "      <td>0.168297</td>\n",
       "      <td>1279.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>135992.0</td>\n",
       "      <td>2.096629</td>\n",
       "      <td>-0.005357</td>\n",
       "      <td>-1.977506</td>\n",
       "      <td>0.300357</td>\n",
       "      <td>0.555053</td>\n",
       "      <td>-0.520263</td>\n",
       "      <td>0.044011</td>\n",
       "      <td>-0.075661</td>\n",
       "      <td>0.797991</td>\n",
       "      <td>-0.335600</td>\n",
       "      <td>-1.314290</td>\n",
       "      <td>-0.957375</td>\n",
       "      <td>-1.612116</td>\n",
       "      <td>-0.518824</td>\n",
       "      <td>0.487759</td>\n",
       "      <td>0.502801</td>\n",
       "      <td>0.429880</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.200395</td>\n",
       "      <td>-0.250111</td>\n",
       "      <td>-0.413232</td>\n",
       "      <td>-1.169915</td>\n",
       "      <td>0.296059</td>\n",
       "      <td>-0.117854</td>\n",
       "      <td>-0.260555</td>\n",
       "      <td>0.216644</td>\n",
       "      <td>-0.072525</td>\n",
       "      <td>-0.039778</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>156412.0</td>\n",
       "      <td>1.930480</td>\n",
       "      <td>-0.293869</td>\n",
       "      <td>-0.260770</td>\n",
       "      <td>0.479326</td>\n",
       "      <td>-0.654627</td>\n",
       "      <td>-0.725121</td>\n",
       "      <td>-0.334856</td>\n",
       "      <td>-0.164048</td>\n",
       "      <td>1.102093</td>\n",
       "      <td>-0.209092</td>\n",
       "      <td>-0.605723</td>\n",
       "      <td>1.144234</td>\n",
       "      <td>1.245244</td>\n",
       "      <td>-0.257659</td>\n",
       "      <td>0.527831</td>\n",
       "      <td>0.138758</td>\n",
       "      <td>-0.603407</td>\n",
       "      <td>-0.334044</td>\n",
       "      <td>-0.095873</td>\n",
       "      <td>-0.098033</td>\n",
       "      <td>-0.149455</td>\n",
       "      <td>-0.283249</td>\n",
       "      <td>0.335576</td>\n",
       "      <td>0.034443</td>\n",
       "      <td>-0.401095</td>\n",
       "      <td>-0.631618</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>-0.023239</td>\n",
       "      <td>34.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  TimeElapsed        F1        F2        F3        F4        F5  \\\n",
       "0      1     137696.0  2.065791 -0.065613 -1.130470  0.384728 -0.075736   \n",
       "1      2     161961.0  2.095037 -1.175449 -1.520765 -0.918477 -0.481096   \n",
       "2      3     153055.0 -0.584961 -4.600653 -2.430893  0.969314 -0.657150   \n",
       "3      4     135992.0  2.096629 -0.005357 -1.977506  0.300357  0.555053   \n",
       "4      5     156412.0  1.930480 -0.293869 -0.260770  0.479326 -0.654627   \n",
       "\n",
       "         F6        F7        F8        F9       F10       F11       F12  \\\n",
       "0 -1.128309  0.186186 -0.326402  0.551486  0.071902 -0.873314  0.389151   \n",
       "1 -0.488949 -0.525732 -0.273566 -0.063873  0.759856 -1.797146 -0.866861   \n",
       "2  2.225950  0.971258  0.299291  1.152448 -0.865479  0.643267  0.995614   \n",
       "3 -0.520263  0.044011 -0.075661  0.797991 -0.335600 -1.314290 -0.957375   \n",
       "4 -0.725121 -0.334856 -0.164048  1.102093 -0.209092 -0.605723  1.144234   \n",
       "\n",
       "        F13       F14       F15       F16       F17       F18       F19  \\\n",
       "0  0.088783  0.267724  0.051437 -0.061622 -0.341495 -0.820560  0.200598   \n",
       "1  0.405156 -0.354675 -0.022158  1.091197 -0.107480 -0.757384  0.795549   \n",
       "2 -0.669748  0.648798  0.435696 -0.542873  0.119842 -0.757992 -0.603119   \n",
       "3 -1.612116 -0.518824  0.487759  0.502801  0.429880  0.001930  0.200395   \n",
       "4  1.245244 -0.257659  0.527831  0.138758 -0.603407 -0.334044 -0.095873   \n",
       "\n",
       "        F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0 -0.212461 -0.296821 -0.728288  0.318849 -0.110236 -0.280067  0.204709   \n",
       "1  0.181253  0.565300  1.580267 -0.318744 -0.901549  0.403101  0.302833   \n",
       "2  2.248672  0.461198 -1.349655 -0.676798 -0.975495 -0.972022 -1.120256   \n",
       "3 -0.250111 -0.413232 -1.169915  0.296059 -0.117854 -0.260555  0.216644   \n",
       "4 -0.098033 -0.149455 -0.283249  0.335576  0.034443 -0.401095 -0.631618   \n",
       "\n",
       "        F27       F28   Amount  Status  \n",
       "0 -0.071613 -0.060814     5.37       0  \n",
       "1 -0.034751 -0.058508   104.40       0  \n",
       "2 -0.154142  0.168297  1279.42       0  \n",
       "3 -0.072525 -0.039778     5.49       0  \n",
       "4  0.037459 -0.023239    34.99       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"finsecure_train.csv\")\n",
    "test_df=pd.read_csv(\"finsecure_test.csv\")\n",
    "\n",
    "print(\"Training Data Shape:\", train_df.shape)\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37661988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Shape: (6560, 31)\n",
      "\n",
      "First 5 rows of testing data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>TimeElapsed</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>162693.0</td>\n",
       "      <td>2.104774</td>\n",
       "      <td>0.140612</td>\n",
       "      <td>-1.934892</td>\n",
       "      <td>0.279430</td>\n",
       "      <td>0.724530</td>\n",
       "      <td>-0.477268</td>\n",
       "      <td>0.165560</td>\n",
       "      <td>-0.180432</td>\n",
       "      <td>0.516740</td>\n",
       "      <td>-0.388601</td>\n",
       "      <td>-0.997106</td>\n",
       "      <td>0.031812</td>\n",
       "      <td>0.247469</td>\n",
       "      <td>-0.889824</td>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.415079</td>\n",
       "      <td>0.323476</td>\n",
       "      <td>-0.227015</td>\n",
       "      <td>0.188957</td>\n",
       "      <td>-0.138074</td>\n",
       "      <td>-0.393971</td>\n",
       "      <td>-1.015716</td>\n",
       "      <td>0.276825</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.196325</td>\n",
       "      <td>0.210785</td>\n",
       "      <td>-0.059701</td>\n",
       "      <td>-0.036394</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>90085.0</td>\n",
       "      <td>-1.376939</td>\n",
       "      <td>1.414134</td>\n",
       "      <td>-1.391369</td>\n",
       "      <td>-0.299312</td>\n",
       "      <td>1.219036</td>\n",
       "      <td>0.626913</td>\n",
       "      <td>-0.075954</td>\n",
       "      <td>0.996870</td>\n",
       "      <td>0.732388</td>\n",
       "      <td>-1.449992</td>\n",
       "      <td>1.947084</td>\n",
       "      <td>-1.678410</td>\n",
       "      <td>1.872420</td>\n",
       "      <td>1.306923</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>-0.277804</td>\n",
       "      <td>1.928200</td>\n",
       "      <td>0.430611</td>\n",
       "      <td>-0.880894</td>\n",
       "      <td>-0.322090</td>\n",
       "      <td>0.328227</td>\n",
       "      <td>1.172930</td>\n",
       "      <td>-0.287420</td>\n",
       "      <td>-1.741269</td>\n",
       "      <td>-0.610010</td>\n",
       "      <td>-0.095282</td>\n",
       "      <td>0.042049</td>\n",
       "      <td>0.052398</td>\n",
       "      <td>22.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>74839.0</td>\n",
       "      <td>-0.606393</td>\n",
       "      <td>1.269511</td>\n",
       "      <td>0.218814</td>\n",
       "      <td>-0.415976</td>\n",
       "      <td>0.586030</td>\n",
       "      <td>0.284010</td>\n",
       "      <td>0.226725</td>\n",
       "      <td>0.616568</td>\n",
       "      <td>-0.689347</td>\n",
       "      <td>-0.564948</td>\n",
       "      <td>-0.225548</td>\n",
       "      <td>0.137278</td>\n",
       "      <td>0.284057</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.293227</td>\n",
       "      <td>1.211234</td>\n",
       "      <td>-0.696036</td>\n",
       "      <td>0.974640</td>\n",
       "      <td>0.844511</td>\n",
       "      <td>0.074814</td>\n",
       "      <td>-0.281852</td>\n",
       "      <td>-0.915233</td>\n",
       "      <td>-0.170885</td>\n",
       "      <td>-1.455177</td>\n",
       "      <td>0.062658</td>\n",
       "      <td>0.164310</td>\n",
       "      <td>0.111451</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>9.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>145288.0</td>\n",
       "      <td>-0.549750</td>\n",
       "      <td>0.198439</td>\n",
       "      <td>-0.708078</td>\n",
       "      <td>-2.042136</td>\n",
       "      <td>1.402134</td>\n",
       "      <td>-0.630856</td>\n",
       "      <td>0.456403</td>\n",
       "      <td>-0.341079</td>\n",
       "      <td>-0.902612</td>\n",
       "      <td>0.584973</td>\n",
       "      <td>0.550115</td>\n",
       "      <td>-0.948392</td>\n",
       "      <td>-0.644923</td>\n",
       "      <td>-1.428510</td>\n",
       "      <td>-1.146831</td>\n",
       "      <td>1.306669</td>\n",
       "      <td>0.625490</td>\n",
       "      <td>-0.440405</td>\n",
       "      <td>1.069339</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>-0.027659</td>\n",
       "      <td>0.148023</td>\n",
       "      <td>-0.308642</td>\n",
       "      <td>-0.001331</td>\n",
       "      <td>-0.655368</td>\n",
       "      <td>-0.467096</td>\n",
       "      <td>-0.037675</td>\n",
       "      <td>0.036312</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>61600.0</td>\n",
       "      <td>1.154670</td>\n",
       "      <td>-0.158841</td>\n",
       "      <td>0.653590</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>-0.518939</td>\n",
       "      <td>-0.136887</td>\n",
       "      <td>-0.328912</td>\n",
       "      <td>-0.061967</td>\n",
       "      <td>0.367292</td>\n",
       "      <td>-0.165987</td>\n",
       "      <td>-0.880670</td>\n",
       "      <td>0.560167</td>\n",
       "      <td>1.549028</td>\n",
       "      <td>-0.299369</td>\n",
       "      <td>1.339456</td>\n",
       "      <td>0.854272</td>\n",
       "      <td>-0.942832</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.086439</td>\n",
       "      <td>0.157735</td>\n",
       "      <td>-0.005702</td>\n",
       "      <td>-0.083031</td>\n",
       "      <td>-0.113571</td>\n",
       "      <td>-0.395754</td>\n",
       "      <td>0.279485</td>\n",
       "      <td>0.433003</td>\n",
       "      <td>-0.012163</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>71.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  TimeElapsed        F1        F2        F3        F4        F5  \\\n",
       "0      1     162693.0  2.104774  0.140612 -1.934892  0.279430  0.724530   \n",
       "1      2      90085.0 -1.376939  1.414134 -1.391369 -0.299312  1.219036   \n",
       "2      3      74839.0 -0.606393  1.269511  0.218814 -0.415976  0.586030   \n",
       "3      4     145288.0 -0.549750  0.198439 -0.708078 -2.042136  1.402134   \n",
       "4      5      61600.0  1.154670 -0.158841  0.653590  0.408600 -0.518939   \n",
       "\n",
       "         F6        F7        F8        F9       F10       F11       F12  \\\n",
       "0 -0.477268  0.165560 -0.180432  0.516740 -0.388601 -0.997106  0.031812   \n",
       "1  0.626913 -0.075954  0.996870  0.732388 -1.449992  1.947084 -1.678410   \n",
       "2  0.284010  0.226725  0.616568 -0.689347 -0.564948 -0.225548  0.137278   \n",
       "3 -0.630856  0.456403 -0.341079 -0.902612  0.584973  0.550115 -0.948392   \n",
       "4 -0.136887 -0.328912 -0.061967  0.367292 -0.165987 -0.880670  0.560167   \n",
       "\n",
       "        F13       F14       F15       F16       F17       F18       F19  \\\n",
       "0  0.247469 -0.889824  0.283221  0.415079  0.323476 -0.227015  0.188957   \n",
       "1  1.872420  1.306923  0.008918 -0.277804  1.928200  0.430611 -0.880894   \n",
       "2  0.284057  0.002446  0.293227  1.211234 -0.696036  0.974640  0.844511   \n",
       "3 -0.644923 -1.428510 -1.146831  1.306669  0.625490 -0.440405  1.069339   \n",
       "4  1.549028 -0.299369  1.339456  0.854272 -0.942832  0.141282 -0.086439   \n",
       "\n",
       "        F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0 -0.138074 -0.393971 -1.015716  0.276825 -0.067104 -0.196325  0.210785   \n",
       "1 -0.322090  0.328227  1.172930 -0.287420 -1.741269 -0.610010 -0.095282   \n",
       "2  0.074814 -0.281852 -0.915233 -0.170885 -1.455177  0.062658  0.164310   \n",
       "3  0.004095 -0.027659  0.148023 -0.308642 -0.001331 -0.655368 -0.467096   \n",
       "4  0.157735 -0.005702 -0.083031 -0.113571 -0.395754  0.279485  0.433003   \n",
       "\n",
       "        F27       F28  Amount  \n",
       "0 -0.059701 -0.036394    1.98  \n",
       "1  0.042049  0.052398   22.49  \n",
       "2  0.111451  0.008747    9.42  \n",
       "3 -0.037675  0.036312   10.00  \n",
       "4 -0.012163  0.031846   71.21  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing Data Shape:\", test_df.shape)\n",
    "print(\"\\nFirst 5 rows of testing data:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ffdcc8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5c8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      " 0\n",
      "\n",
      "Class Distribution:\n",
      "0    9545\n",
      "1     295\n",
      "Name: Status, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Description of 'Amount' and 'TimeElapsed':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeElapsed</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9840.000000</td>\n",
       "      <td>9840.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94877.251931</td>\n",
       "      <td>84.800888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47557.118344</td>\n",
       "      <td>213.586895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54215.250000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84877.000000</td>\n",
       "      <td>20.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139306.000000</td>\n",
       "      <td>74.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172768.000000</td>\n",
       "      <td>3974.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TimeElapsed       Amount\n",
       "count    9840.000000  9840.000000\n",
       "mean    94877.251931    84.800888\n",
       "std     47557.118344   213.586895\n",
       "min         0.000000     0.000000\n",
       "25%     54215.250000     5.000000\n",
       "50%     84877.000000    20.950000\n",
       "75%    139306.000000    74.955000\n",
       "max    172768.000000  3974.580000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Missing values in training data:\\n\", train_df.isnull().sum().sum())\n",
    "\n",
    "status_counts = train_df['Status'].value_counts()\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(status_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='Status', data=train_df)\n",
    "plt.title('Distribution of Transaction Status (0: Normal, 1: Anomalous)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDescription of 'Amount' and 'TimeElapsed':\")\n",
    "train_df[['TimeElapsed', 'Amount']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae5f74",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d46c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Data Shape: (9840, 30)\n",
      "Data has been scaled. First 10 rows of scaled training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeElapsed</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900410</td>\n",
       "      <td>0.926345</td>\n",
       "      <td>-0.106805</td>\n",
       "      <td>-0.405587</td>\n",
       "      <td>0.153313</td>\n",
       "      <td>-0.002160</td>\n",
       "      <td>-0.803027</td>\n",
       "      <td>0.183091</td>\n",
       "      <td>-0.213457</td>\n",
       "      <td>0.501373</td>\n",
       "      <td>0.139951</td>\n",
       "      <td>-0.789558</td>\n",
       "      <td>0.348744</td>\n",
       "      <td>0.103263</td>\n",
       "      <td>0.286580</td>\n",
       "      <td>0.052547</td>\n",
       "      <td>0.036673</td>\n",
       "      <td>-0.089587</td>\n",
       "      <td>-0.740358</td>\n",
       "      <td>0.209751</td>\n",
       "      <td>-0.303318</td>\n",
       "      <td>-0.325490</td>\n",
       "      <td>-0.965203</td>\n",
       "      <td>0.489402</td>\n",
       "      <td>-0.174439</td>\n",
       "      <td>-0.510243</td>\n",
       "      <td>0.414810</td>\n",
       "      <td>-0.155772</td>\n",
       "      <td>-0.197785</td>\n",
       "      <td>-0.371909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410665</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>-0.716946</td>\n",
       "      <td>-0.578331</td>\n",
       "      <td>-0.630245</td>\n",
       "      <td>-0.242777</td>\n",
       "      <td>-0.326813</td>\n",
       "      <td>-0.180191</td>\n",
       "      <td>-0.180945</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.553440</td>\n",
       "      <td>-1.530613</td>\n",
       "      <td>-0.437889</td>\n",
       "      <td>0.422911</td>\n",
       "      <td>-0.100476</td>\n",
       "      <td>-0.027417</td>\n",
       "      <td>0.950782</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>-0.678479</td>\n",
       "      <td>0.915442</td>\n",
       "      <td>0.226589</td>\n",
       "      <td>0.545166</td>\n",
       "      <td>2.079997</td>\n",
       "      <td>-0.492715</td>\n",
       "      <td>-1.476879</td>\n",
       "      <td>0.776483</td>\n",
       "      <td>0.617428</td>\n",
       "      <td>-0.076773</td>\n",
       "      <td>-0.190679</td>\n",
       "      <td>0.091766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.223386</td>\n",
       "      <td>-0.190323</td>\n",
       "      <td>-2.599976</td>\n",
       "      <td>-0.981154</td>\n",
       "      <td>0.504799</td>\n",
       "      <td>-0.347280</td>\n",
       "      <td>1.695326</td>\n",
       "      <td>0.583701</td>\n",
       "      <td>0.171553</td>\n",
       "      <td>0.986781</td>\n",
       "      <td>-0.423453</td>\n",
       "      <td>0.426974</td>\n",
       "      <td>0.728568</td>\n",
       "      <td>-0.663118</td>\n",
       "      <td>0.523561</td>\n",
       "      <td>0.470063</td>\n",
       "      <td>-0.344927</td>\n",
       "      <td>0.166792</td>\n",
       "      <td>-0.679074</td>\n",
       "      <td>-0.743565</td>\n",
       "      <td>3.009176</td>\n",
       "      <td>0.440033</td>\n",
       "      <td>-1.784844</td>\n",
       "      <td>-1.044245</td>\n",
       "      <td>-1.598590</td>\n",
       "      <td>-1.813518</td>\n",
       "      <td>-2.321135</td>\n",
       "      <td>-0.332637</td>\n",
       "      <td>0.507970</td>\n",
       "      <td>5.593413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.864578</td>\n",
       "      <td>0.939336</td>\n",
       "      <td>-0.073679</td>\n",
       "      <td>-0.780485</td>\n",
       "      <td>0.102585</td>\n",
       "      <td>0.372269</td>\n",
       "      <td>-0.350137</td>\n",
       "      <td>0.110541</td>\n",
       "      <td>-0.059168</td>\n",
       "      <td>0.700479</td>\n",
       "      <td>-0.104974</td>\n",
       "      <td>-1.143288</td>\n",
       "      <td>-0.494577</td>\n",
       "      <td>-1.615238</td>\n",
       "      <td>-0.202557</td>\n",
       "      <td>0.526632</td>\n",
       "      <td>0.484223</td>\n",
       "      <td>0.339090</td>\n",
       "      <td>0.065250</td>\n",
       "      <td>0.209510</td>\n",
       "      <td>-0.353993</td>\n",
       "      <td>-0.443054</td>\n",
       "      <td>-1.547751</td>\n",
       "      <td>0.454297</td>\n",
       "      <td>-0.186979</td>\n",
       "      <td>-0.473492</td>\n",
       "      <td>0.439456</td>\n",
       "      <td>-0.157726</td>\n",
       "      <td>-0.132985</td>\n",
       "      <td>-0.371347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.293978</td>\n",
       "      <td>0.869343</td>\n",
       "      <td>-0.232291</td>\n",
       "      <td>-0.020659</td>\n",
       "      <td>0.210191</td>\n",
       "      <td>-0.345782</td>\n",
       "      <td>-0.502721</td>\n",
       "      <td>-0.082789</td>\n",
       "      <td>-0.113555</td>\n",
       "      <td>0.946109</td>\n",
       "      <td>-0.028938</td>\n",
       "      <td>-0.574908</td>\n",
       "      <td>0.821648</td>\n",
       "      <td>1.271692</td>\n",
       "      <td>-0.040145</td>\n",
       "      <td>0.570172</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>-0.235140</td>\n",
       "      <td>-0.263828</td>\n",
       "      <td>-0.141904</td>\n",
       "      <td>-0.149307</td>\n",
       "      <td>-0.176666</td>\n",
       "      <td>-0.378155</td>\n",
       "      <td>0.515168</td>\n",
       "      <td>0.063690</td>\n",
       "      <td>-0.738195</td>\n",
       "      <td>-1.312137</td>\n",
       "      <td>0.077977</td>\n",
       "      <td>-0.082036</td>\n",
       "      <td>-0.233223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.275015</td>\n",
       "      <td>-0.331420</td>\n",
       "      <td>-0.266724</td>\n",
       "      <td>0.593931</td>\n",
       "      <td>-1.577975</td>\n",
       "      <td>-0.553082</td>\n",
       "      <td>-0.363752</td>\n",
       "      <td>-0.138104</td>\n",
       "      <td>0.226998</td>\n",
       "      <td>-2.294346</td>\n",
       "      <td>0.473045</td>\n",
       "      <td>0.355671</td>\n",
       "      <td>-0.065709</td>\n",
       "      <td>0.846806</td>\n",
       "      <td>0.100264</td>\n",
       "      <td>-0.904737</td>\n",
       "      <td>0.177210</td>\n",
       "      <td>0.123192</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>-0.572130</td>\n",
       "      <td>-0.321531</td>\n",
       "      <td>0.122292</td>\n",
       "      <td>0.590170</td>\n",
       "      <td>-0.244839</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.567777</td>\n",
       "      <td>-0.385108</td>\n",
       "      <td>-0.114937</td>\n",
       "      <td>-0.047997</td>\n",
       "      <td>-0.094584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.782546</td>\n",
       "      <td>-0.413894</td>\n",
       "      <td>0.886845</td>\n",
       "      <td>-0.597847</td>\n",
       "      <td>-1.058485</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>-0.780310</td>\n",
       "      <td>0.800423</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>-0.297316</td>\n",
       "      <td>-0.553745</td>\n",
       "      <td>-1.337715</td>\n",
       "      <td>-0.615684</td>\n",
       "      <td>-1.362186</td>\n",
       "      <td>-0.035584</td>\n",
       "      <td>-0.514070</td>\n",
       "      <td>0.685785</td>\n",
       "      <td>0.142242</td>\n",
       "      <td>0.251791</td>\n",
       "      <td>-1.577794</td>\n",
       "      <td>-0.441640</td>\n",
       "      <td>0.058693</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>-0.534130</td>\n",
       "      <td>-0.104050</td>\n",
       "      <td>0.575734</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>-0.603593</td>\n",
       "      <td>0.434433</td>\n",
       "      <td>-0.369615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.130487</td>\n",
       "      <td>-1.569930</td>\n",
       "      <td>1.376711</td>\n",
       "      <td>-2.235203</td>\n",
       "      <td>1.993985</td>\n",
       "      <td>-0.358013</td>\n",
       "      <td>-1.381500</td>\n",
       "      <td>-1.591286</td>\n",
       "      <td>-0.619186</td>\n",
       "      <td>-0.887581</td>\n",
       "      <td>-2.269138</td>\n",
       "      <td>3.325396</td>\n",
       "      <td>-4.028928</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>-6.072900</td>\n",
       "      <td>2.681903</td>\n",
       "      <td>-4.434296</td>\n",
       "      <td>-3.449869</td>\n",
       "      <td>-1.737073</td>\n",
       "      <td>3.522117</td>\n",
       "      <td>-0.257780</td>\n",
       "      <td>1.654864</td>\n",
       "      <td>1.031065</td>\n",
       "      <td>0.103641</td>\n",
       "      <td>1.289109</td>\n",
       "      <td>-1.608491</td>\n",
       "      <td>-0.021958</td>\n",
       "      <td>-2.286241</td>\n",
       "      <td>5.452114</td>\n",
       "      <td>-0.391527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.742582</td>\n",
       "      <td>-0.103731</td>\n",
       "      <td>0.524678</td>\n",
       "      <td>0.700914</td>\n",
       "      <td>-0.171179</td>\n",
       "      <td>0.179584</td>\n",
       "      <td>-0.403894</td>\n",
       "      <td>0.471060</td>\n",
       "      <td>-0.059750</td>\n",
       "      <td>-0.325533</td>\n",
       "      <td>-0.104143</td>\n",
       "      <td>-0.667167</td>\n",
       "      <td>0.213192</td>\n",
       "      <td>0.869286</td>\n",
       "      <td>0.099847</td>\n",
       "      <td>0.870915</td>\n",
       "      <td>0.331295</td>\n",
       "      <td>-0.242177</td>\n",
       "      <td>-0.209494</td>\n",
       "      <td>0.204649</td>\n",
       "      <td>0.202201</td>\n",
       "      <td>-0.279683</td>\n",
       "      <td>-0.831390</td>\n",
       "      <td>-0.138166</td>\n",
       "      <td>-0.180931</td>\n",
       "      <td>-0.175389</td>\n",
       "      <td>0.197849</td>\n",
       "      <td>0.573895</td>\n",
       "      <td>0.351828</td>\n",
       "      <td>-0.376029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.381293</td>\n",
       "      <td>-0.124808</td>\n",
       "      <td>0.217973</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>-0.022982</td>\n",
       "      <td>1.643616</td>\n",
       "      <td>2.608176</td>\n",
       "      <td>0.076723</td>\n",
       "      <td>0.572720</td>\n",
       "      <td>-0.521160</td>\n",
       "      <td>0.184459</td>\n",
       "      <td>-0.231833</td>\n",
       "      <td>-0.052839</td>\n",
       "      <td>0.027388</td>\n",
       "      <td>0.387684</td>\n",
       "      <td>1.559437</td>\n",
       "      <td>0.113948</td>\n",
       "      <td>-0.223558</td>\n",
       "      <td>0.448025</td>\n",
       "      <td>1.260518</td>\n",
       "      <td>0.580692</td>\n",
       "      <td>-0.183478</td>\n",
       "      <td>-0.813874</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>1.591465</td>\n",
       "      <td>0.302872</td>\n",
       "      <td>-0.826566</td>\n",
       "      <td>0.635408</td>\n",
       "      <td>0.318262</td>\n",
       "      <td>-0.233645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimeElapsed        F1        F2        F3        F4        F5        F6  \\\n",
       "0     0.900410  0.926345 -0.106805 -0.405587  0.153313 -0.002160 -0.803027   \n",
       "1     1.410665  0.938665 -0.716946 -0.578331 -0.630245 -0.242777 -0.326813   \n",
       "2     1.223386 -0.190323 -2.599976 -0.981154  0.504799 -0.347280  1.695326   \n",
       "3     0.864578  0.939336 -0.073679 -0.780485  0.102585  0.372269 -0.350137   \n",
       "4     1.293978  0.869343 -0.232291 -0.020659  0.210191 -0.345782 -0.502721   \n",
       "5    -0.275015 -0.331420 -0.266724  0.593931 -1.577975 -0.553082 -0.363752   \n",
       "6     0.782546 -0.413894  0.886845 -0.597847 -1.058485  0.984505 -0.780310   \n",
       "7    -0.130487 -1.569930  1.376711 -2.235203  1.993985 -0.358013 -1.381500   \n",
       "8    -0.742582 -0.103731  0.524678  0.700914 -0.171179  0.179584 -0.403894   \n",
       "9    -0.381293 -0.124808  0.217973  0.008618 -0.022982  1.643616  2.608176   \n",
       "\n",
       "         F7        F8        F9       F10       F11       F12       F13  \\\n",
       "0  0.183091 -0.213457  0.501373  0.139951 -0.789558  0.348744  0.103263   \n",
       "1 -0.180191 -0.180945  0.004336  0.553440 -1.530613 -0.437889  0.422911   \n",
       "2  0.583701  0.171553  0.986781 -0.423453  0.426974  0.728568 -0.663118   \n",
       "3  0.110541 -0.059168  0.700479 -0.104974 -1.143288 -0.494577 -1.615238   \n",
       "4 -0.082789 -0.113555  0.946109 -0.028938 -0.574908  0.821648  1.271692   \n",
       "5 -0.138104  0.226998 -2.294346  0.473045  0.355671 -0.065709  0.846806   \n",
       "6  0.800423  0.045880 -0.297316 -0.553745 -1.337715 -0.615684 -1.362186   \n",
       "7 -1.591286 -0.619186 -0.887581 -2.269138  3.325396 -4.028928  0.019246   \n",
       "8  0.471060 -0.059750 -0.325533 -0.104143 -0.667167  0.213192  0.869286   \n",
       "9  0.076723  0.572720 -0.521160  0.184459 -0.231833 -0.052839  0.027388   \n",
       "\n",
       "        F14       F15       F16       F17       F18       F19       F20  \\\n",
       "0  0.286580  0.052547  0.036673 -0.089587 -0.740358  0.209751 -0.303318   \n",
       "1 -0.100476 -0.027417  0.950782  0.040462 -0.678479  0.915442  0.226589   \n",
       "2  0.523561  0.470063 -0.344927  0.166792 -0.679074 -0.743565  3.009176   \n",
       "3 -0.202557  0.526632  0.484223  0.339090  0.065250  0.209510 -0.353993   \n",
       "4 -0.040145  0.570172  0.195561 -0.235140 -0.263828 -0.141904 -0.149307   \n",
       "5  0.100264 -0.904737  0.177210  0.123192  0.873786 -0.572130 -0.321531   \n",
       "6 -0.035584 -0.514070  0.685785  0.142242  0.251791 -1.577794 -0.441640   \n",
       "7 -6.072900  2.681903 -4.434296 -3.449869 -1.737073  3.522117 -0.257780   \n",
       "8  0.099847  0.870915  0.331295 -0.242177 -0.209494  0.204649  0.202201   \n",
       "9  0.387684  1.559437  0.113948 -0.223558  0.448025  1.260518  0.580692   \n",
       "\n",
       "        F21       F22       F23       F24       F25       F26       F27  \\\n",
       "0 -0.325490 -0.965203  0.489402 -0.174439 -0.510243  0.414810 -0.155772   \n",
       "1  0.545166  2.079997 -0.492715 -1.476879  0.776483  0.617428 -0.076773   \n",
       "2  0.440033 -1.784844 -1.044245 -1.598590 -1.813518 -2.321135 -0.332637   \n",
       "3 -0.443054 -1.547751  0.454297 -0.186979 -0.473492  0.439456 -0.157726   \n",
       "4 -0.176666 -0.378155  0.515168  0.063690 -0.738195 -1.312137  0.077977   \n",
       "5  0.122292  0.590170 -0.244839  0.020548  0.567777 -0.385108 -0.114937   \n",
       "6  0.058693 -0.053767 -0.534130 -0.104050  0.575734  0.763833 -0.603593   \n",
       "7  1.654864  1.031065  0.103641  1.289109 -1.608491 -0.021958 -2.286241   \n",
       "8 -0.279683 -0.831390 -0.138166 -0.180931 -0.175389  0.197849  0.573895   \n",
       "9 -0.183478 -0.813874  0.038417  1.591465  0.302872 -0.826566  0.635408   \n",
       "\n",
       "        F28    Amount  \n",
       "0 -0.197785 -0.371909  \n",
       "1 -0.190679  0.091766  \n",
       "2  0.507970  5.593413  \n",
       "3 -0.132985 -0.371347  \n",
       "4 -0.082036 -0.233223  \n",
       "5 -0.047997 -0.094584  \n",
       "6  0.434433 -0.369615  \n",
       "7  5.452114 -0.391527  \n",
       "8  0.351828 -0.376029  \n",
       "9  0.318262 -0.233645  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [col for col in train_df.columns if col not in ['Index', 'Status']]\n",
    "X = train_df[features]\n",
    "y = train_df['Status']\n",
    "\n",
    "X_submission = test_df[features]\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_submission_scaled = scaler.transform(X_submission)\n",
    "\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "X_submission_scaled = pd.DataFrame(X_submission_scaled, columns=features)\n",
    "\n",
    "print(\"Scaled Data Shape:\", X_scaled.shape)\n",
    "print(\"Data has been scaled. First 10 rows of scaled training data:\")\n",
    "X_scaled.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf9c67",
   "metadata": {},
   "source": [
    "# Train-Validation Split\n",
    "\n",
    "We split our training data into a training subset and a validation subset (80/20 split). \n",
    "\n",
    "This allows us to train the models and then evaluate their performance on unseen data to choose the best one, without touching the final test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c76e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split shape: (7872, 30)\n",
      "Validation split shape: (1968, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training split shape:\", X_train.shape)\n",
    "print(\"Validation split shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705df18",
   "metadata": {},
   "source": [
    "# Initial Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c1cd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Decision Tree ---\n",
      "Validation Results for Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      1.00      0.99      1909\n",
      "Anomalous (1)       0.84      0.81      0.83        59\n",
      "\n",
      "     accuracy                           0.99      1968\n",
      "    macro avg       0.92      0.90      0.91      1968\n",
      " weighted avg       0.99      0.99      0.99      1968\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training KNN ---\n",
      "Validation Results for KNN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      1.00      1.00      1909\n",
      "Anomalous (1)       0.96      0.73      0.83        59\n",
      "\n",
      "     accuracy                           0.99      1968\n",
      "    macro avg       0.97      0.86      0.91      1968\n",
      " weighted avg       0.99      0.99      0.99      1968\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Gaussian NB ---\n",
      "Validation Results for Gaussian NB:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      0.97      0.98      1909\n",
      "Anomalous (1)       0.46      0.80      0.58        59\n",
      "\n",
      "     accuracy                           0.97      1968\n",
      "    macro avg       0.73      0.88      0.78      1968\n",
      " weighted avg       0.98      0.97      0.97      1968\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training SVM ---\n",
      "Validation Results for SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      0.99      0.99      1909\n",
      "Anomalous (1)       0.71      0.76      0.74        59\n",
      "\n",
      "     accuracy                           0.98      1968\n",
      "    macro avg       0.85      0.88      0.86      1968\n",
      " weighted avg       0.98      0.98      0.98      1968\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Validation Results for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      1.00      1.00      1909\n",
      "Anomalous (1)       0.96      0.81      0.88        59\n",
      "\n",
      "     accuracy                           0.99      1968\n",
      "    macro avg       0.98      0.91      0.94      1968\n",
      " weighted avg       0.99      0.99      0.99      1968\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training AdaBoost ---\n",
      "Validation Results for AdaBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      1.00      1.00      1909\n",
      "Anomalous (1)       0.86      0.83      0.84        59\n",
      "\n",
      "     accuracy                           0.99      1968\n",
      "    macro avg       0.93      0.91      0.92      1968\n",
      " weighted avg       0.99      0.99      0.99      1968\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Bagging ---\n",
      "Validation Results for Bagging:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      1.00      1.00      1909\n",
      "Anomalous (1)       0.92      0.83      0.88        59\n",
      "\n",
      "     accuracy                           0.99      1968\n",
      "    macro avg       0.96      0.91      0.94      1968\n",
      " weighted avg       0.99      0.99      0.99      1968\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=10),\n",
    "    \"Gaussian NB\": GaussianNB(),\n",
    "    \"SVM\": SVC(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Bagging\": BaggingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Training {name} ---\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    print(f\"Validation Results for {name}:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=['Normal (0)', 'Anomalous (1)']))\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6ba4d",
   "metadata": {},
   "source": [
    "We observe that Random Forest provides a very strong balance of precision and recall for the 'Anomalous (1)' class, resulting in a high F1-score, making it the best choice for further optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d4078",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02e0c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Hyperparameter Tuning for Random Forest ---\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/mac/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters Found: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Validation Results for Tuned Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Normal (0)       0.99      1.00      1.00      1909\n",
      "Anomalous (1)       0.96      0.81      0.88        59\n",
      "\n",
      "     accuracy                           0.99      1968\n",
      "    macro avg       0.98      0.91      0.94      1968\n",
      " weighted avg       0.99      0.99      0.99      1968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    param_grid=param_grid,\n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"--- Starting Hyperparameter Tuning for Random Forest ---\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"\\nBest Parameters Found:\", grid_search.best_params_)\n",
    "\n",
    "print(\"\\nValidation Results for Tuned Random Forest:\")\n",
    "y_pred_tuned = best_rf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred_tuned, target_names=['Normal (0)', 'Anomalous (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee6cea",
   "metadata": {},
   "source": [
    "# Final Model Training and Submission File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a66f5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating predictions for the test set ---\n",
      "\n",
      "Submission file 'submission_optimized_RF.csv' has been created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  Status\n",
       "0      1       0\n",
       "1      2       0\n",
       "2      3       0\n",
       "3      4       0\n",
       "4      5       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "print(\"--- Generating predictions for the test set ---\")\n",
    "final_predictions = final_model.predict(X_submission_scaled)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Index\": test_df[\"Index\"],\n",
    "    \"Status\": final_predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"submission_1.csv\", index=False)\n",
    "\n",
    "print(\"\\nSubmission file 'submission_optimized_RF.csv' has been created successfully!\")\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e39720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
